{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## import libraries",
   "id": "d49eae88c5e216a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T10:26:57.685325Z",
     "start_time": "2025-01-21T10:26:56.717512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from cadv_exploration.utils import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "from scripts.python.utils import setup_logger\n",
    "from llm.langchain.downstream_task_prompt import CD_TASK_DESCRIPTION\n",
    "from inspector.deequ.deequ_inspector_manager import DeequInspectorManager\n",
    "from llm.langchain import LangChainCADV\n",
    "from data_models import Constraints\n",
    "\n",
    "from loader import FileLoader\n",
    "\n",
    "from cadv_exploration.dq_manager import DeequDataQualityManager\n",
    "from cadv_exploration.utils import get_project_root\n",
    "import pandas as pd\n",
    "\n",
    "logger = setup_logger(\"toy_example.log\")"
   ],
   "id": "37e1edb112312661",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haochen/Library/Caches/pypoetry/virtualenvs/cadv-exploration-4wWqlI_J-py3.9/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load the data",
   "id": "b1392370a0b77df8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T10:27:03.971805Z",
     "start_time": "2025-01-21T10:27:01.106574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dq_manager = DeequDataQualityManager()\n",
    "train_file_path = get_project_root() / \"data\" / \"toy_example\" / \"files\" / \"hospitalisations_train.csv\"\n",
    "test_file_path = get_project_root() / \"data\" / \"toy_example\" / \"files\" / \"hospitalisations_test.csv\"\n",
    "train_data = FileLoader.load_csv(train_file_path, na_values=[\"NULL\"])\n",
    "test_data = FileLoader.load_csv(test_file_path, na_values=[\"NULL\"])\n",
    "spark_train_data, spark_train = dq_manager.spark_df_from_pandas_df(train_data)\n",
    "spark_validation_data, spark_validation = dq_manager.spark_df_from_pandas_df(test_data)"
   ],
   "id": "4e329ba3a87f2f1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/haochen/Library/Caches/pypoetry/virtualenvs/cadv-exploration-4wWqlI_J-py3.9/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/haochen/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/haochen/.ivy2/jars\n",
      "com.amazon.deequ#deequ added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-9997ded6-8731-46f1-b31d-e72eb52351fb;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.amazon.deequ#deequ;2.0.7-spark-3.5 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.10 in local-m2-cache\n",
      "\tfound org.scalanlp#breeze_2.12;2.1.0 in local-m2-cache\n",
      "\tfound org.scalanlp#breeze-macros_2.12;2.1.0 in local-m2-cache\n",
      "\tfound org.typelevel#spire_2.12;0.17.0 in local-m2-cache\n",
      "\tfound org.typelevel#spire-macros_2.12;0.17.0 in local-m2-cache\n",
      "\tfound org.typelevel#algebra_2.12;2.0.1 in local-m2-cache\n",
      "\tfound org.typelevel#cats-kernel_2.12;2.1.1 in local-m2-cache\n",
      "\tfound org.typelevel#spire-platform_2.12;0.17.0 in local-m2-cache\n",
      "\tfound org.typelevel#spire-util_2.12;0.17.0 in local-m2-cache\n",
      "\tfound dev.ludovic.netlib#blas;3.0.1 in local-m2-cache\n",
      "\tfound dev.ludovic.netlib#lapack;3.0.1 in local-m2-cache\n",
      "\tfound dev.ludovic.netlib#arpack;3.0.1 in local-m2-cache\n",
      "\tfound net.sf.opencsv#opencsv;2.3 in local-m2-cache\n",
      "\tfound com.github.wendykierp#JTransforms;3.1 in local-m2-cache\n",
      "\tfound pl.edu.icm#JLargeArrays;1.5 in local-m2-cache\n",
      "\tfound org.apache.commons#commons-math3;3.2 in local-m2-cache\n",
      "\tfound org.slf4j#slf4j-api;1.7.5 in local-m2-cache\n",
      "\tfound org.scala-lang.modules#scala-collection-compat_2.12;2.7.0 in local-m2-cache\n",
      ":: resolution report :: resolve 206ms :: artifacts dl 10ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazon.deequ#deequ;2.0.7-spark-3.5 from central in [default]\n",
      "\tcom.github.wendykierp#JTransforms;3.1 from local-m2-cache in [default]\n",
      "\tdev.ludovic.netlib#arpack;3.0.1 from local-m2-cache in [default]\n",
      "\tdev.ludovic.netlib#blas;3.0.1 from local-m2-cache in [default]\n",
      "\tdev.ludovic.netlib#lapack;3.0.1 from local-m2-cache in [default]\n",
      "\tnet.sf.opencsv#opencsv;2.3 from local-m2-cache in [default]\n",
      "\torg.apache.commons#commons-math3;3.2 from local-m2-cache in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.10 from local-m2-cache in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.7.0 from local-m2-cache in [default]\n",
      "\torg.scalanlp#breeze-macros_2.12;2.1.0 from local-m2-cache in [default]\n",
      "\torg.scalanlp#breeze_2.12;2.1.0 from local-m2-cache in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.5 from local-m2-cache in [default]\n",
      "\torg.typelevel#algebra_2.12;2.0.1 from local-m2-cache in [default]\n",
      "\torg.typelevel#cats-kernel_2.12;2.1.1 from local-m2-cache in [default]\n",
      "\torg.typelevel#spire-macros_2.12;0.17.0 from local-m2-cache in [default]\n",
      "\torg.typelevel#spire-platform_2.12;0.17.0 from local-m2-cache in [default]\n",
      "\torg.typelevel#spire-util_2.12;0.17.0 from local-m2-cache in [default]\n",
      "\torg.typelevel#spire_2.12;0.17.0 from local-m2-cache in [default]\n",
      "\tpl.edu.icm#JLargeArrays;1.5 from local-m2-cache in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.scala-lang#scala-reflect;2.12.15 by [org.scala-lang#scala-reflect;2.12.10] in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.2.0 by [org.scala-lang.modules#scala-collection-compat_2.12;2.7.0] in [default]\n",
      "\torg.apache.commons#commons-math3;3.5 by [org.apache.commons#commons-math3;3.2] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   22  |   0   |   0   |   3   ||   19  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-9997ded6-8731-46f1-b31d-e72eb52351fb\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 19 already retrieved (0kB/5ms)\n",
      "25/01/21 11:27:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## get constraints with deequ",
   "id": "390efdabb51d2cd2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T10:27:11.961780Z",
     "start_time": "2025-01-21T10:27:07.000472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "constraints = dq_manager.get_constraints_for_spark_df(spark_train, spark_train_data, spark_validation,\n",
    "                                                      spark_validation_data)\n",
    "constraints.to_dict()"
   ],
   "id": "1d1472b9e7634846",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/21 11:27:07 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Callback server started!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'constraints': {'admission_day': {'code': [['.isComplete(\"admission_day\")',\n",
       "     'Invalid'],\n",
       "    ['.isNonNegative(\"admission_day\")', 'Valid']],\n",
       "   'assumptions': []},\n",
       "  'bloodtype': {'code': [['.isComplete(\"bloodtype\")', 'Valid'],\n",
       "    ['.isContainedIn(\"bloodtype\", [\"A pos\", \"O pos\"])', 'Invalid']],\n",
       "   'assumptions': []},\n",
       "  'complications': {'code': [['.isComplete(\"complications\")', 'Valid'],\n",
       "    ['.isContainedIn(\"complications\", [\"N\"])', 'Invalid']],\n",
       "   'assumptions': []},\n",
       "  'cost': {'code': [['.isComplete(\"cost\")', 'Valid'],\n",
       "    ['.isNonNegative(\"cost\")', 'Valid']],\n",
       "   'assumptions': []},\n",
       "  'diagnosis': {'code': [['.isComplete(\"diagnosis\")', 'Invalid']],\n",
       "   'assumptions': []},\n",
       "  'discharge_day': {'code': [['.isComplete(\"discharge_day\")', 'Valid'],\n",
       "    ['.isNonNegative(\"discharge_day\")', 'Valid'],\n",
       "    ['.isUnique(\"discharge_day\")', 'Valid']],\n",
       "   'assumptions': []},\n",
       "  'gender': {'code': [['.isComplete(\"gender\")', 'Invalid'],\n",
       "    ['.isNonNegative(\"gender\")', 'Valid']],\n",
       "   'assumptions': []},\n",
       "  'insurance': {'code': [['.isComplete(\"insurance\")', 'Valid']],\n",
       "   'assumptions': []},\n",
       "  'race': {'code': [['.isComplete(\"race\")', 'Valid']], 'assumptions': []},\n",
       "  'ssn': {'code': [['.isComplete(\"ssn\")', 'Valid'],\n",
       "    ['.isUnique(\"ssn\")', 'Valid']],\n",
       "   'assumptions': []}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## validate constraints on test data",
   "id": "7c2113319138c9e7"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-21T10:27:21.221285Z",
     "start_time": "2025-01-21T10:27:19.947146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "code_column_map = constraints.get_suggestions_code_column_map(valid_only=False)\n",
    "code_list = [item for item in code_column_map.keys()]\n",
    "spark_test_data, spark_test = dq_manager.spark_df_from_pandas_df(test_data)\n",
    "status_on_test_data = dq_manager.validate_on_spark_df(spark_test, spark_test_data, code_list,\n",
    "                                                      return_raw=True)\n",
    "code_list_for_constraints = [\n",
    "    (code_list[i], status_on_test_data[i].constraint_status, status_on_test_data[i].constraint_message) for i\n",
    "    in\n",
    "    range(len(code_list))]\n",
    "writable_code_list_for_constraints = [f\"{item[0]}, {item[1]}, {item[2]}\" for item in code_list_for_constraints]\n",
    "pd.DataFrame(code_list_for_constraints, columns=[\"column_name\", \"constraint_status\", \"constraint_message\"])\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                        column_name constraint_status  \\\n",
       "0                               .isComplete(\"race\")           Success   \n",
       "1                      .isComplete(\"admission_day\")           Failure   \n",
       "2                   .isNonNegative(\"admission_day\")           Success   \n",
       "3                                .isComplete(\"ssn\")           Success   \n",
       "4                                  .isUnique(\"ssn\")           Success   \n",
       "5   .isContainedIn(\"bloodtype\", [\"A pos\", \"O pos\"])           Failure   \n",
       "6                          .isComplete(\"bloodtype\")           Success   \n",
       "7                          .isComplete(\"insurance\")           Success   \n",
       "8                      .isComplete(\"discharge_day\")           Success   \n",
       "9                   .isNonNegative(\"discharge_day\")           Success   \n",
       "10                       .isUnique(\"discharge_day\")           Success   \n",
       "11                         .isComplete(\"diagnosis\")           Failure   \n",
       "12                              .isComplete(\"cost\")           Success   \n",
       "13                           .isNonNegative(\"cost\")           Success   \n",
       "14                            .isComplete(\"gender\")           Failure   \n",
       "15                         .isNonNegative(\"gender\")           Success   \n",
       "16           .isContainedIn(\"complications\", [\"N\"])           Failure   \n",
       "17                     .isComplete(\"complications\")           Success   \n",
       "\n",
       "                                   constraint_message  \n",
       "0                                                      \n",
       "1   Value: 0.6666666666666666 does not meet the co...  \n",
       "2                                                      \n",
       "3                                                      \n",
       "4                                                      \n",
       "5   Value: 0.6666666666666666 does not meet the co...  \n",
       "6                                                      \n",
       "7                                                      \n",
       "8                                                      \n",
       "9                                                      \n",
       "10                                                     \n",
       "11  Value: 0.6666666666666666 does not meet the co...  \n",
       "12                                                     \n",
       "13                                                     \n",
       "14  Value: 0.6666666666666666 does not meet the co...  \n",
       "15                                                     \n",
       "16  Value: 0.6666666666666666 does not meet the co...  \n",
       "17                                                     "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>constraint_status</th>\n",
       "      <th>constraint_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.isComplete(\"race\")</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.isComplete(\"admission_day\")</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Value: 0.6666666666666666 does not meet the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.isNonNegative(\"admission_day\")</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.isComplete(\"ssn\")</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.isUnique(\"ssn\")</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>.isContainedIn(\"bloodtype\", [\"A pos\", \"O pos\"])</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Value: 0.6666666666666666 does not meet the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>.isComplete(\"bloodtype\")</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>.isComplete(\"insurance\")</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.isComplete(\"discharge_day\")</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>.isNonNegative(\"discharge_day\")</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>.isUnique(\"discharge_day\")</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>.isComplete(\"diagnosis\")</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Value: 0.6666666666666666 does not meet the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>.isComplete(\"cost\")</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>.isNonNegative(\"cost\")</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>.isComplete(\"gender\")</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Value: 0.6666666666666666 does not meet the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>.isNonNegative(\"gender\")</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>.isContainedIn(\"complications\", [\"N\"])</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Value: 0.6666666666666666 does not meet the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>.isComplete(\"complications\")</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## prepare context for LLM",
   "id": "a59e0eec9d6450ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T10:27:28.186497Z",
     "start_time": "2025-01-21T10:27:27.571866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "column_desc = DeequInspectorManager().spark_df_to_column_desc(spark_train_data, spark_train)\n",
    "context = \"\"\"\n",
    "nonsensitive_df = duckdb.sql(\"SELECT * EXCLUDE ssn, gender, race\n",
    "FROM 's3://datalake/latest/hospitalisations.csv'\").df()\n",
    "hosp_df = nonsensitive_df.dropna()\n",
    "strokes_total = duckdb.sql(\"SELECT COUNT(*) FROM hosp_df\n",
    "WHERE diagnosis = 'stroke'\").fetch()\n",
    "strokes_for_rare_bloodtypes = duckdb.sql(\"SELECT COUNT(*)\n",
    "FROM hosp_df WHERE diagnosis = 'stroke'\n",
    "AND bloodtype IN ('AB negative', 'B negative')\").fetch()\n",
    "generate_report(strokes_total, strokes_for_rare_bloodtypes)\"\"\"\n",
    "result_path_cadv = \"toy_example_cadv_constraints.yaml\""
   ],
   "id": "cdd7d9faf4b74f8f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T10:27:30.712778Z",
     "start_time": "2025-01-21T10:27:30.709406Z"
    }
   },
   "cell_type": "code",
   "source": "## run LLM on toy model with default settings",
   "id": "154de9c6e1d72693",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T10:27:44.862541Z",
     "start_time": "2025-01-21T10:27:32.319608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lc = LangChainCADV(model_name=\"gpt-4o\", downstream_task_description=CD_TASK_DESCRIPTION,\n",
    "                   assumption_generation_trick=None, logger=logger)\n",
    "\n",
    "relevant_columns_list, expectations, suggestions = lc.invoke(\n",
    "    input_variables={\"column_desc\": column_desc, \"script\": context},\n",
    "    num_stages=3,\n",
    "    max_retries=3\n",
    ")\n",
    "code_list_for_constraints = [item for v in suggestions.values() for item in v]\n",
    "\n",
    "# Validate the constraints on the original data to see if they are grammarly correct\n",
    "code_list_for_constraints_valid = dq_manager.filter_constraints(code_list_for_constraints, spark_validation,\n",
    "                                                                spark_validation_data)\n",
    "constraints = Constraints.from_llm_output(relevant_columns_list, expectations, suggestions,\n",
    "                                          code_list_for_constraints_valid)\n",
    "\n",
    "constraints.to_dict()"
   ],
   "id": "9d75a7daad9c8737",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'constraints': {'bloodtype': {'code': [[\".isContainedIn('bloodtype', ['A positive', 'A negative', 'B positive', 'B negative', 'AB positive', 'AB negative', 'O positive', 'O negative'])\",\n",
       "     'Invalid']],\n",
       "   'assumptions': [\"The column should support the presence of 'AB negative' and 'B negative' as valid blood types.\"]},\n",
       "  'diagnosis': {'code': [[\".isContainedIn('diagnosis', ['stroke', 'heart attack', 'pneumonia', 'diabetes', 'cancer', 'flu', 'asthma', 'allergy', 'infection', 'fracture', 'sprain', 'burn', 'laceration', 'migraine', 'arthritis', 'depression', 'anxiety', 'hypertension', 'covid-19', 'common cold'])\",\n",
       "     'Invalid']],\n",
       "   'assumptions': [\"The column should contain the value 'stroke' as a valid diagnosis.\"]}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## run LLM on toy model with add_deequ trick\n",
    "\n",
    "It will add, delete and modify the constraints generated by deequ"
   ],
   "id": "330b66a1daeb54a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T10:30:34.808330Z",
     "start_time": "2025-01-21T10:30:22.180714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "deequ_assumptions = dq_manager.get_constraints_for_spark_df(spark_train, spark_train_data).to_string()\n",
    "lc = LangChainCADV(model_name=\"gpt-4o\", downstream_task_description=CD_TASK_DESCRIPTION,\n",
    "                   assumption_generation_trick='add_deequ', logger=logger)\n",
    "\n",
    "relevant_columns_list, expectations, suggestions = lc.invoke(\n",
    "    input_variables={\"column_desc\": column_desc, \"script\": context, \"deequ_assumptions\": deequ_assumptions},\n",
    "    num_stages=3,\n",
    "    max_retries=3\n",
    ")\n",
    "code_list_for_constraints = [item for v in suggestions.values() for item in v]\n",
    "\n",
    "# Validate the constraints on the original data to see if they are grammarly correct\n",
    "code_list_for_constraints_valid = dq_manager.filter_constraints(code_list_for_constraints, spark_validation,\n",
    "                                                                spark_validation_data)\n",
    "constraints = Constraints.from_llm_output(relevant_columns_list, expectations, suggestions,\n",
    "                                          code_list_for_constraints_valid)\n",
    "\n",
    "constraints.to_dict()"
   ],
   "id": "328460bacf4b46f4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'constraints': {'bloodtype': {'code': [[\".isComplete('bloodtype')\", 'Valid'],\n",
       "    [\".isContainedIn('bloodtype', ['A positive', 'A negative', 'B positive', 'B negative', 'AB positive', 'AB negative', 'O positive', 'O negative'])\",\n",
       "     'Invalid']],\n",
       "   'assumptions': [\"The 'bloodtype' column should be complete, with no missing values.\",\n",
       "    \"The 'bloodtype' column should expect to contain values such as 'AB negative' and 'B negative'.\"]},\n",
       "  'diagnosis': {'code': [[\".isComplete('diagnosis')\", 'Invalid'],\n",
       "    [\".isContainedIn('diagnosis', ['stroke', 'heart attack', 'cancer', 'diabetes', 'asthma', 'allergy', 'flu', 'covid-19', 'pneumonia', 'bronchitis'])\",\n",
       "     'Invalid']],\n",
       "   'assumptions': [\"The 'diagnosis' column should be complete, with no missing values.\",\n",
       "    \"The 'diagnosis' column should contain the value 'stroke'.\"]}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "## run LLM on toy model with add_experience trick",
   "id": "a218e79a42ad456a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T10:31:50.780585Z",
     "start_time": "2025-01-21T10:31:30.810401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lc = LangChainCADV(model_name=\"gpt-4o\", downstream_task_description=CD_TASK_DESCRIPTION,\n",
    "                   assumption_generation_trick=\"add_experience\", logger=logger)\n",
    "\n",
    "relevant_columns_list, expectations, suggestions = lc.invoke(\n",
    "    input_variables={\"column_desc\": column_desc, \"script\": context},\n",
    "    num_stages=3,\n",
    "    max_retries=3\n",
    ")\n",
    "code_list_for_constraints = [item for v in suggestions.values() for item in v]\n",
    "\n",
    "# Validate the constraints on the original data to see if they are grammarly correct\n",
    "code_list_for_constraints_valid = dq_manager.filter_constraints(code_list_for_constraints, spark_validation,\n",
    "                                                                spark_validation_data)\n",
    "constraints = Constraints.from_llm_output(relevant_columns_list, expectations, suggestions,\n",
    "                                          code_list_for_constraints_valid)\n",
    "\n",
    "constraints.to_dict()"
   ],
   "id": "364baf35bd6d5029",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'constraints': {'bloodtype': {'code': [[\".isComplete('bloodtype')\", 'Valid'],\n",
       "    [\".isContainedIn('bloodtype', ['O pos', 'A pos', 'AB negative', 'B negative', 'O neg', 'A neg', 'B pos', 'AB pos'])\",\n",
       "     'Invalid']],\n",
       "   'assumptions': ['The column should be NOT NULL.',\n",
       "    \"The column should have values in ['O pos', 'A pos', 'AB negative', 'B negative'] and possibly other blood types.\",\n",
       "    \"The column should have an IS IN constraint with values ['O pos', 'A pos', 'AB negative', 'B negative'].\"]},\n",
       "  'diagnosis': {'code': [[\".isComplete('diagnosis')\", 'Invalid'],\n",
       "    [\".isContainedIn('diagnosis', ['cancer', 'cough', 'fraction', 'stroke', 'heart attack', 'diabetes', 'flu', 'pneumonia', 'asthma', 'bronchitis', 'allergy', 'infection', 'migraine', 'anemia', 'arthritis', 'hypertension', 'depression', 'anxiety', 'obesity', 'malaria'])\",\n",
       "     'Invalid']],\n",
       "   'assumptions': ['The column should be NOT NULL.',\n",
       "    \"The column should have values in ['cancer', 'cough', 'fraction', 'stroke'] and possibly other medical conditions.\",\n",
       "    \"The column should have an IS IN constraint with values ['cancer', 'cough', 'fraction', 'stroke'].\"]}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## stop spark",
   "id": "d0a5c80f3b20e679"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "spark_train.sparkContext._gateway.shutdown_callback_server()\n",
    "spark_train.stop()\n",
    "spark_validation.sparkContext._gateway.shutdown_callback_server()\n",
    "spark_validation.stop()"
   ],
   "id": "47301d26e5b93629"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
