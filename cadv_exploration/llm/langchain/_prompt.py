SYSTEM_TASK_DESCRIPTION = """The system is designed to generate context-aware validation rules for a dataset which is used for multiple downstream tasks including machine learning pipeline, data analysis, business intelligence, etc. Context-aware means that the system should be able to understand the user's intuitions and generate validation rules that meet the user's expectations to ensure the data meets the user's expectations.

The system contains the following components:
1. *Relevant Column Target*: Given a dataset described by name, columns with corresponding downstream code. This component finds the columns that are used in the code snippet.
2. *Expectation Extraction*: Given a dataset described by name, columns with corresponding downstream code and the relevant columns. This component generates user's assumptions about these columns.
3. *Rule Generation*: Given a dataset described by name, columns with corresponding downstream code, the relevant columns and the user's assumptions. This component generates formal validation rules for the dataset.
"""

RELEVENT_COLUMN_TARGET_PROMPT = """You are part of a context-aware data validation system.
You serve as the *Relevant Column Target* component. You are asked to find the columns used in the code snippet.
The dataset is a CSV file with the following columns:
{columns}

The user writes the code snippet below:
{code_snippet}

Your response should be a list of comma separated values
eg: `foo, bar, baz` or `foo,bar,baz`
"""

# https://github.com/awslabs/python-deequ/blob/master/pydeequ/checks.py
EXPECTATION_EXTRACTION_PROMPT = """You are part of a context-aware data validation system.
Given that the user may not have a complete understanding of the dataset, you should find the user's intuitions. These intuitions would then be used to generate validation rules to ensure the data meets the user's expectations.


Here are the things you need to consider:
1. Make sure the assumptions are only about the relevant columns generated by the *Relevant Column Target* component.
2. You can generate assumptions for both individual columns and relationships between columns.
3. The assumptions should be in a human-readable format.

The dataset is a CSV file with the following columns:
{columns}

The user writes the code snippet below:

{code_snippet}

The relevant columns generated by the *Relevant Column Target* component are:
{relevant_columns}

Please generate validation rules as a JSON object with the column names as keys and a list of assumptions as values.
e.g., ```{{'column_name_1': ['assumption_1', 'assumption_2', ...], 'column_name_2': ['assumption_1', 'assumption_2', ...], ...}}```
"""

RULE_GENERATION_PROMPT = """You are part of a context-aware data validation system.
You are asked to transform the user's intuitions into formal validation rules to ensure the data meets the user's expectations. We are using PyDeequ as the validation library so the rules should be in PyDeequ format.

The function signature is as follows:
    def hasSize(self, assertion, hint=None):
    def isComplete(self, column, hint=None):
    def hasCompleteness(self, column, assertion, hint=None):
    def areComplete(self, columns, hint=None):
    def haveCompleteness(self, columns, assertion, hint=None):
    def areAnyComplete(self, columns, hint=None):
    def haveAnyCompleteness(self, columns, assertion, hint=None):
    def isUnique(self, column, hint=None):
    def isPrimaryKey(self, column, *columns, hint=None):
    def hasUniqueness(self, columns, assertion, hint=None):
    def hasDistinctness(self, columns, assertion, hint=None):
    def hasUniqueValueRatio(self, columns, assertion, hint=None):
    def hasNumberOfDistinctValues(self, column, assertion, binningUdf, maxBins, hint=None):
    def hasHistogramValues(self, column, assertion, binningUdf, maxBins, hint=None):
    def kllSketchSatisfies(self, column, assertion, kllParameters=None, hint=None):
    def _isNewestPointNonAnomalous(self):
    def hasEntropy(self, column, assertion, hint=None):
    def hasMutualInformation(self, columnA, columnB, assertion, hint=None):
    def hasApproxQuantile(self, column, quantile, assertion, hint=None):
    def hasMinLength(self, column, assertion, hint=None):
    def hasMaxLength(self, column, assertion, hint=None):
    def hasMin(self, column, assertion, hint=None):
    def hasMax(self, column, assertion, hint=None):
    def hasMean(self, column, assertion, hint=None):
    def hasSum(self, column, assertion, hint=None):
    def hasStandardDeviation(self, column, assertion, hint=None):
    def hasApproxCountDistinct(self, column, assertion, hint=None):
    def hasCorrelation(self, columnA, columnB, assertion, hint=None):
    def satisfies(self, columnCondition, constraintName, assertion=None, hint=None):
    def hasPattern(self, column, pattern, assertion=None, name=None, hint=None):
    def containsCreditCardNumber(self, column, assertion=None, hint=None):
    def containsEmail(self, column, assertion=None, hint=None):
    def containsURL(self, column, assertion=None, hint=None):
    def containsSocialSecurityNumber(self, column, assertion=None, hint=None):
    def hasDataType(self, column, datatype: ConstrainableDataTypes, assertion=None, hint=None):
    def isNonNegative(self, column, assertion=None, hint=None):
    def isPositive(self, column, assertion=None, hint=None):
    def isLessThan(self, columnA, columnB, assertion=None, hint=None):
    def isLessThanOrEqualTo(self, columnA, columnB, assertion=None, hint=None):
    def isGreaterThan(self, columnA, columnB, assertion=None, hint=None):
    def isGreaterThanOrEqualTo(self, columnA, columnB, assertion=None, hint=None):
    def isContainedIn(self, column, allowed_values, assertion=None, hint=None):

The Intuitions generated by the *Expectation Extraction* component are:
{expectations}
Please generate a list of PyDeequ validation rules for the dataset.
For example:
[isComplete('column_name_1'), hasSize(lambda x: x >= 3), ...]
"""
